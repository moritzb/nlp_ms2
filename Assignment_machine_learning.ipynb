{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6x3Hn9MIb9k"
      },
      "source": [
        "# Assignment <span style=\"color:red\">option Four</span> - News Categorization using PyTorch\n",
        "\n",
        "Download the dataset from https://www.kaggle.com/uciml/news-aggregator-dataset and develop a news classification or categorization model. The dataset contain only titles of a news item and some metadata. The categories of the news items include one of: –<span  style=\"color:red\"> b</span> : business – <span  style=\"color:red\">t</span> : science and technology – <span  style=\"color:red\">e</span> : entertainment and –<span  style=\"color:red\">m</span> : health.\n",
        "\n",
        "1. Prepare training and test dataset: Split the data into training and test set (80% train and 20% test). Make sure they are balanced, otherwise if all <span  style=\"color:red\">b</span> files are on training, your model fails to predict <span  style=\"color:red\">t</span> files in test.\n",
        "2. Binary classification: produce training data for each two categories, such as <span  style=\"color:red\">b </span> and <span  style=\"color:red\"> t</span>, <span  style=\"color:red\">b</span> and <span  style=\"color:red\"> m</span>, <span  style=\"color:red\">e</span> and <span  style=\"color:red\">t</span> and so on. Evaluate the performance and report which categories are easier for the models.\n",
        "3. Adapt the Text Categorization PyTorch code (see above) and evaluate the performance of the system for these task\n",
        "4. Use a pre-trained embeddings and compare your result. When you use pre-trained embeddings, you have to average the word embeddings of each tokens in ach document to get the unique representation of the document. DOC_EMBEDDING = (TOKEN1_EMBEDDING + ... + TOKENn_EMBEDDING). You can also use some of the <span  style=\"color:red\">spacy/FLAIR </span>document embedding methods\n",
        "5. Report the recall, precision, and F1 scores for both binary and multi-class classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StkThUu-If-a",
        "outputId": "6b3c415e-e8d4-47b9-c526-3bf126cb9943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwyNWM5nr-jL"
      },
      "source": [
        "# Task 1\n",
        "\n",
        "1. Prepare training and test dataset: Split the data into training and test set (80% train and 20% test). Make sure they are balanced, otherwise if all <span  style=\"color:red\">b</span> files are on training, your model fails to predict <span  style=\"color:red\">t</span> files in test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RnOhGjir-jM",
        "outputId": "c7a099b9-39de-4432-9494-f6f43df4d83b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainingsdaten:  337935\n",
            "Testdaten:  84484\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# read data\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/uci-news-aggregator.csv\")\n",
        "# remove unnecessary columns\n",
        "frame = data[[\"TITLE\", \"CATEGORY\"]]\n",
        "\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "# Division into training and test data. The stratify parameter causes the \"Category\" feature to be split equally\n",
        "training_data, testing_data = train_test_split(\n",
        "    frame, test_size=TEST_SIZE, random_state=0, stratify=data[\"CATEGORY\"]\n",
        ")\n",
        "\n",
        "# print size of train and test set\n",
        "print(\"Trainingsdaten: \", len(training_data))\n",
        "print(\"Testdaten: \", len(testing_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLqPPvzgr-jO"
      },
      "source": [
        "# Task 2\n",
        "\n",
        "Binary classification: produce training data for each two categories, such as b and t, b\n",
        "and m, e and t and so on. Evaluate the performance and report which categories are\n",
        "easier for the models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WI4nJ3Wr-jP",
        "outputId": "2046c38a-bb94-4589-f504-5c024f375b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------\n",
            "Category Pair: b (1) vs t (0)\n",
            "------------------PERFORMANCE-----------------------------\n",
            "Accuracy: 0.93\n",
            "Precision: 0.93\n",
            "Recall: 0.93\n",
            "F1_score: 0.93\n",
            "--------------------REPORT--------------------------------\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.92     21669\n",
            "           1       0.93      0.93      0.93     23193\n",
            "\n",
            "    accuracy                           0.93     44862\n",
            "   macro avg       0.93      0.93      0.93     44862\n",
            "weighted avg       0.93      0.93      0.93     44862\n",
            "\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "Category Pair: b (1) vs e (0)\n",
            "------------------PERFORMANCE-----------------------------\n",
            "Accuracy: 0.98\n",
            "Precision: 0.98\n",
            "Recall: 0.97\n",
            "F1_score: 0.97\n",
            "--------------------REPORT--------------------------------\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     30494\n",
            "           1       0.98      0.97      0.97     23193\n",
            "\n",
            "    accuracy                           0.98     53687\n",
            "   macro avg       0.98      0.98      0.98     53687\n",
            "weighted avg       0.98      0.98      0.98     53687\n",
            "\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "Category Pair: b (1) vs m (0)\n",
            "------------------PERFORMANCE-----------------------------\n",
            "Accuracy: 0.97\n",
            "Precision: 0.97\n",
            "Recall: 0.99\n",
            "F1_score: 0.99\n",
            "--------------------REPORT--------------------------------\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95      9128\n",
            "           1       0.97      0.99      0.98     23193\n",
            "\n",
            "    accuracy                           0.97     32321\n",
            "   macro avg       0.97      0.96      0.97     32321\n",
            "weighted avg       0.97      0.97      0.97     32321\n",
            "\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "Category Pair: t (1) vs e (0)\n",
            "------------------PERFORMANCE-----------------------------\n",
            "Accuracy: 0.98\n",
            "Precision: 0.97\n",
            "Recall: 0.97\n",
            "F1_score: 0.97\n",
            "--------------------REPORT--------------------------------\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     30494\n",
            "           1       0.97      0.97      0.97     21669\n",
            "\n",
            "    accuracy                           0.98     52163\n",
            "   macro avg       0.98      0.98      0.98     52163\n",
            "weighted avg       0.98      0.98      0.98     52163\n",
            "\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "Category Pair: t (1) vs m (0)\n",
            "------------------PERFORMANCE-----------------------------\n",
            "Accuracy: 0.98\n",
            "Precision: 0.97\n",
            "Recall: 0.99\n",
            "F1_score: 0.99\n",
            "--------------------REPORT--------------------------------\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96      9128\n",
            "           1       0.97      0.99      0.98     21669\n",
            "\n",
            "    accuracy                           0.98     30797\n",
            "   macro avg       0.98      0.97      0.97     30797\n",
            "weighted avg       0.98      0.98      0.98     30797\n",
            "\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n",
            "Category Pair: e (1) vs m (0)\n",
            "------------------PERFORMANCE-----------------------------\n",
            "Accuracy: 0.98\n",
            "Precision: 0.98\n",
            "Recall: 0.99\n",
            "F1_score: 0.99\n",
            "--------------------REPORT--------------------------------\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95      9128\n",
            "           1       0.98      0.99      0.99     30494\n",
            "\n",
            "    accuracy                           0.98     39622\n",
            "   macro avg       0.98      0.96      0.97     39622\n",
            "weighted avg       0.98      0.98      0.98     39622\n",
            "\n",
            "----------------------------------------------------------\n",
            "----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "from itertools import combinations\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# otherwise google colab caused warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Define the categories\n",
        "categories = [\"b\", \"t\", \"e\", \"m\"]\n",
        "\n",
        "# get all possible combinations\n",
        "combinations_categories = list(combinations(categories, 2))\n",
        "\n",
        "# print combinations\n",
        "# for combination in possible_combinations:\n",
        "#    print(combination)\n",
        "\n",
        "# loop through each category combination\n",
        "for category_pair in combinations_categories:\n",
        "    category_1, category_2 = category_pair\n",
        "\n",
        "    # only keep data of category pair\n",
        "    filtered_training_data = training_data[\n",
        "        (training_data[\"CATEGORY\"] == category_1)\n",
        "        | (training_data[\"CATEGORY\"] == category_2)\n",
        "    ]\n",
        "    filtered_test_data = testing_data[\n",
        "        (testing_data[\"CATEGORY\"] == category_1)\n",
        "        | (testing_data[\"CATEGORY\"] == category_2)\n",
        "    ]\n",
        "\n",
        "    # Create a binary dataset for the current category pair\n",
        "    cat_mapping = {category_1: 1, category_2: 0}\n",
        "    filtered_training_data[\"CATEGORY_IN_BINARY\"] = filtered_training_data[\n",
        "        \"CATEGORY\"\n",
        "    ].map(cat_mapping)\n",
        "    filtered_test_data[\"CATEGORY_IN_BINARY\"] = filtered_test_data[\"CATEGORY\"].map(\n",
        "        cat_mapping\n",
        "    )\n",
        "\n",
        "    # print(filtered_training_data)\n",
        "\n",
        "    # split the binary dataset into features (X) und labels (y)\n",
        "    X_train = filtered_training_data[\"TITLE\"]\n",
        "    y_train = filtered_training_data[\"CATEGORY_IN_BINARY\"]\n",
        "    X_test = filtered_test_data[\"TITLE\"]\n",
        "    y_test = filtered_test_data[\"CATEGORY_IN_BINARY\"]\n",
        "\n",
        "    # vectorize the titles using TF-IDF\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    # train a Naive Bayes classifier\n",
        "    classifier = MultinomialNB()\n",
        "    classifier.fit(X_train_tfidf, y_train)\n",
        "    # make predictions on the test set\n",
        "    predictions = classifier.predict(X_test_tfidf)\n",
        "\n",
        "    # evaluate performance\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    # this report gives further information\n",
        "    report = classification_report(y_test, predictions)\n",
        "\n",
        "    # print results\n",
        "    print(\"----------------------------------------------------------\")\n",
        "    print(\n",
        "        f\"Category Pair: {category_1} ({cat_mapping[category_1]}) vs {category_2} ({cat_mapping[category_2]})\"\n",
        "    )\n",
        "    print(\"------------------PERFORMANCE-----------------------------\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1_score: {f1:.2f}\")\n",
        "    print(\"--------------------REPORT--------------------------------\")\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "    print(\"----------------------------------------------------------\")\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT_Ao7jPr-jQ"
      },
      "source": [
        "# Task 3\n",
        "\n",
        "Adapt the Text Categorization PyTorch code (see above) and evaluate the performance\n",
        "of the system for these task\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg_zbCysYO_B",
        "outputId": "ed5c1a4b-f6b2-4034-c28d-79fbef226d3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verwendetes Gerät: cuda\n",
            "Tesla T4\n",
            "Epoch [1/1], Step [4/2252], Loss: 1.2641\n",
            "Epoch [1/1], Step [8/2252], Loss: 0.9883\n",
            "Epoch [1/1], Step [12/2252], Loss: 0.7994\n",
            "Epoch [1/1], Step [16/2252], Loss: 0.7469\n",
            "Epoch [1/1], Step [20/2252], Loss: 0.6942\n",
            "Epoch [1/1], Step [24/2252], Loss: 0.5984\n",
            "Epoch [1/1], Step [28/2252], Loss: 0.4539\n",
            "Epoch [1/1], Step [32/2252], Loss: 0.6396\n",
            "Epoch [1/1], Step [36/2252], Loss: 0.4627\n",
            "Epoch [1/1], Step [40/2252], Loss: 0.5199\n",
            "Epoch [1/1], Step [44/2252], Loss: 0.5514\n",
            "Epoch [1/1], Step [48/2252], Loss: 0.5017\n",
            "Epoch [1/1], Step [52/2252], Loss: 0.4160\n",
            "Epoch [1/1], Step [56/2252], Loss: 0.3625\n",
            "Epoch [1/1], Step [60/2252], Loss: 0.4309\n",
            "Epoch [1/1], Step [64/2252], Loss: 0.3307\n",
            "Epoch [1/1], Step [68/2252], Loss: 0.3857\n",
            "Epoch [1/1], Step [72/2252], Loss: 0.3860\n",
            "Epoch [1/1], Step [76/2252], Loss: 0.3305\n",
            "Epoch [1/1], Step [80/2252], Loss: 0.5032\n",
            "Epoch [1/1], Step [84/2252], Loss: 0.3794\n",
            "Epoch [1/1], Step [88/2252], Loss: 0.4986\n",
            "Epoch [1/1], Step [92/2252], Loss: 0.3892\n",
            "Epoch [1/1], Step [96/2252], Loss: 0.2895\n",
            "Epoch [1/1], Step [100/2252], Loss: 0.2891\n",
            "Epoch [1/1], Step [104/2252], Loss: 0.3306\n",
            "Epoch [1/1], Step [108/2252], Loss: 0.3978\n",
            "Epoch [1/1], Step [112/2252], Loss: 0.2919\n",
            "Epoch [1/1], Step [116/2252], Loss: 0.2832\n",
            "Epoch [1/1], Step [120/2252], Loss: 0.3550\n",
            "Epoch [1/1], Step [124/2252], Loss: 0.2392\n",
            "Epoch [1/1], Step [128/2252], Loss: 0.3531\n",
            "Epoch [1/1], Step [132/2252], Loss: 0.3701\n",
            "Epoch [1/1], Step [136/2252], Loss: 0.4509\n",
            "Epoch [1/1], Step [140/2252], Loss: 0.3517\n",
            "Epoch [1/1], Step [144/2252], Loss: 0.2895\n",
            "Epoch [1/1], Step [148/2252], Loss: 0.3122\n",
            "Epoch [1/1], Step [152/2252], Loss: 0.2461\n",
            "Epoch [1/1], Step [156/2252], Loss: 0.2175\n",
            "Epoch [1/1], Step [160/2252], Loss: 0.4166\n",
            "Epoch [1/1], Step [164/2252], Loss: 0.3123\n",
            "Epoch [1/1], Step [168/2252], Loss: 0.2520\n",
            "Epoch [1/1], Step [172/2252], Loss: 0.2128\n",
            "Epoch [1/1], Step [176/2252], Loss: 0.2351\n",
            "Epoch [1/1], Step [180/2252], Loss: 0.2718\n",
            "Epoch [1/1], Step [184/2252], Loss: 0.2774\n",
            "Epoch [1/1], Step [188/2252], Loss: 0.2250\n",
            "Epoch [1/1], Step [192/2252], Loss: 0.2505\n",
            "Epoch [1/1], Step [196/2252], Loss: 0.2057\n",
            "Epoch [1/1], Step [200/2252], Loss: 0.2440\n",
            "Epoch [1/1], Step [204/2252], Loss: 0.2920\n",
            "Epoch [1/1], Step [208/2252], Loss: 0.2579\n",
            "Epoch [1/1], Step [212/2252], Loss: 0.1902\n",
            "Epoch [1/1], Step [216/2252], Loss: 0.2527\n",
            "Epoch [1/1], Step [220/2252], Loss: 0.2609\n",
            "Epoch [1/1], Step [224/2252], Loss: 0.3801\n",
            "Epoch [1/1], Step [228/2252], Loss: 0.2784\n",
            "Epoch [1/1], Step [232/2252], Loss: 0.1797\n",
            "Epoch [1/1], Step [236/2252], Loss: 0.2603\n",
            "Epoch [1/1], Step [240/2252], Loss: 0.2214\n",
            "Epoch [1/1], Step [244/2252], Loss: 0.3274\n",
            "Epoch [1/1], Step [248/2252], Loss: 0.2102\n",
            "Epoch [1/1], Step [252/2252], Loss: 0.2797\n",
            "Epoch [1/1], Step [256/2252], Loss: 0.3137\n",
            "Epoch [1/1], Step [260/2252], Loss: 0.2979\n",
            "Epoch [1/1], Step [264/2252], Loss: 0.2699\n",
            "Epoch [1/1], Step [268/2252], Loss: 0.1921\n",
            "Epoch [1/1], Step [272/2252], Loss: 0.2221\n",
            "Epoch [1/1], Step [276/2252], Loss: 0.1533\n",
            "Epoch [1/1], Step [280/2252], Loss: 0.1785\n",
            "Epoch [1/1], Step [284/2252], Loss: 0.1820\n",
            "Epoch [1/1], Step [288/2252], Loss: 0.2573\n",
            "Epoch [1/1], Step [292/2252], Loss: 0.2169\n",
            "Epoch [1/1], Step [296/2252], Loss: 0.2131\n",
            "Epoch [1/1], Step [300/2252], Loss: 0.2605\n",
            "Epoch [1/1], Step [304/2252], Loss: 0.2366\n",
            "Epoch [1/1], Step [308/2252], Loss: 0.2154\n",
            "Epoch [1/1], Step [312/2252], Loss: 0.2992\n",
            "Epoch [1/1], Step [316/2252], Loss: 0.2591\n",
            "Epoch [1/1], Step [320/2252], Loss: 0.1892\n",
            "Epoch [1/1], Step [324/2252], Loss: 0.2419\n",
            "Epoch [1/1], Step [328/2252], Loss: 0.2027\n",
            "Epoch [1/1], Step [332/2252], Loss: 0.1624\n",
            "Epoch [1/1], Step [336/2252], Loss: 0.1623\n",
            "Epoch [1/1], Step [340/2252], Loss: 0.2535\n",
            "Epoch [1/1], Step [344/2252], Loss: 0.2587\n",
            "Epoch [1/1], Step [348/2252], Loss: 0.2949\n",
            "Epoch [1/1], Step [352/2252], Loss: 0.2432\n",
            "Epoch [1/1], Step [356/2252], Loss: 0.3242\n",
            "Epoch [1/1], Step [360/2252], Loss: 0.1950\n",
            "Epoch [1/1], Step [364/2252], Loss: 0.2599\n",
            "Epoch [1/1], Step [368/2252], Loss: 0.2491\n",
            "Epoch [1/1], Step [372/2252], Loss: 0.2234\n",
            "Epoch [1/1], Step [376/2252], Loss: 0.2578\n",
            "Epoch [1/1], Step [380/2252], Loss: 0.2674\n",
            "Epoch [1/1], Step [384/2252], Loss: 0.1755\n",
            "Epoch [1/1], Step [388/2252], Loss: 0.2686\n",
            "Epoch [1/1], Step [392/2252], Loss: 0.3604\n",
            "Epoch [1/1], Step [396/2252], Loss: 0.2080\n",
            "Epoch [1/1], Step [400/2252], Loss: 0.2433\n",
            "Epoch [1/1], Step [404/2252], Loss: 0.2682\n",
            "Epoch [1/1], Step [408/2252], Loss: 0.1689\n",
            "Epoch [1/1], Step [412/2252], Loss: 0.2444\n",
            "Epoch [1/1], Step [416/2252], Loss: 0.2787\n",
            "Epoch [1/1], Step [420/2252], Loss: 0.2442\n",
            "Epoch [1/1], Step [424/2252], Loss: 0.2499\n",
            "Epoch [1/1], Step [428/2252], Loss: 0.2222\n",
            "Epoch [1/1], Step [432/2252], Loss: 0.2963\n",
            "Epoch [1/1], Step [436/2252], Loss: 0.2387\n",
            "Epoch [1/1], Step [440/2252], Loss: 0.2984\n",
            "Epoch [1/1], Step [444/2252], Loss: 0.1574\n",
            "Epoch [1/1], Step [448/2252], Loss: 0.2050\n",
            "Epoch [1/1], Step [452/2252], Loss: 0.1460\n",
            "Epoch [1/1], Step [456/2252], Loss: 0.1446\n",
            "Epoch [1/1], Step [460/2252], Loss: 0.1640\n",
            "Epoch [1/1], Step [464/2252], Loss: 0.2446\n",
            "Epoch [1/1], Step [468/2252], Loss: 0.1155\n",
            "Epoch [1/1], Step [472/2252], Loss: 0.2308\n",
            "Epoch [1/1], Step [476/2252], Loss: 0.1984\n",
            "Epoch [1/1], Step [480/2252], Loss: 0.2583\n",
            "Epoch [1/1], Step [484/2252], Loss: 0.2175\n",
            "Epoch [1/1], Step [488/2252], Loss: 0.2090\n",
            "Epoch [1/1], Step [492/2252], Loss: 0.2043\n",
            "Epoch [1/1], Step [496/2252], Loss: 0.1980\n",
            "Epoch [1/1], Step [500/2252], Loss: 0.2082\n",
            "Epoch [1/1], Step [504/2252], Loss: 0.2840\n",
            "Epoch [1/1], Step [508/2252], Loss: 0.2612\n",
            "Epoch [1/1], Step [512/2252], Loss: 0.3197\n",
            "Epoch [1/1], Step [516/2252], Loss: 0.2488\n",
            "Epoch [1/1], Step [520/2252], Loss: 0.2645\n",
            "Epoch [1/1], Step [524/2252], Loss: 0.2011\n",
            "Epoch [1/1], Step [528/2252], Loss: 0.2451\n",
            "Epoch [1/1], Step [532/2252], Loss: 0.1589\n",
            "Epoch [1/1], Step [536/2252], Loss: 0.2256\n",
            "Epoch [1/1], Step [540/2252], Loss: 0.1512\n",
            "Epoch [1/1], Step [544/2252], Loss: 0.1000\n",
            "Epoch [1/1], Step [548/2252], Loss: 0.2179\n",
            "Epoch [1/1], Step [552/2252], Loss: 0.1875\n",
            "Epoch [1/1], Step [556/2252], Loss: 0.4811\n",
            "Epoch [1/1], Step [560/2252], Loss: 0.1856\n",
            "Epoch [1/1], Step [564/2252], Loss: 0.2245\n",
            "Epoch [1/1], Step [568/2252], Loss: 0.2154\n",
            "Epoch [1/1], Step [572/2252], Loss: 0.3466\n",
            "Epoch [1/1], Step [576/2252], Loss: 0.2376\n",
            "Epoch [1/1], Step [580/2252], Loss: 0.1892\n",
            "Epoch [1/1], Step [584/2252], Loss: 0.2013\n",
            "Epoch [1/1], Step [588/2252], Loss: 0.1914\n",
            "Epoch [1/1], Step [592/2252], Loss: 0.1356\n",
            "Epoch [1/1], Step [596/2252], Loss: 0.2595\n",
            "Epoch [1/1], Step [600/2252], Loss: 0.2008\n",
            "Epoch [1/1], Step [604/2252], Loss: 0.2511\n",
            "Epoch [1/1], Step [608/2252], Loss: 0.1615\n",
            "Epoch [1/1], Step [612/2252], Loss: 0.2499\n",
            "Epoch [1/1], Step [616/2252], Loss: 0.1618\n",
            "Epoch [1/1], Step [620/2252], Loss: 0.2882\n",
            "Epoch [1/1], Step [624/2252], Loss: 0.1710\n",
            "Epoch [1/1], Step [628/2252], Loss: 0.1794\n",
            "Epoch [1/1], Step [632/2252], Loss: 0.1944\n",
            "Epoch [1/1], Step [636/2252], Loss: 0.1812\n",
            "Epoch [1/1], Step [640/2252], Loss: 0.2057\n",
            "Epoch [1/1], Step [644/2252], Loss: 0.2127\n",
            "Epoch [1/1], Step [648/2252], Loss: 0.3059\n",
            "Epoch [1/1], Step [652/2252], Loss: 0.2083\n",
            "Epoch [1/1], Step [656/2252], Loss: 0.1509\n",
            "Epoch [1/1], Step [660/2252], Loss: 0.1222\n",
            "Epoch [1/1], Step [664/2252], Loss: 0.2400\n",
            "Epoch [1/1], Step [668/2252], Loss: 0.1962\n",
            "Epoch [1/1], Step [672/2252], Loss: 0.1623\n",
            "Epoch [1/1], Step [676/2252], Loss: 0.2283\n",
            "Epoch [1/1], Step [680/2252], Loss: 0.2135\n",
            "Epoch [1/1], Step [684/2252], Loss: 0.2267\n",
            "Epoch [1/1], Step [688/2252], Loss: 0.3356\n",
            "Epoch [1/1], Step [692/2252], Loss: 0.1284\n",
            "Epoch [1/1], Step [696/2252], Loss: 0.1626\n",
            "Epoch [1/1], Step [700/2252], Loss: 0.1502\n",
            "Epoch [1/1], Step [704/2252], Loss: 0.2614\n",
            "Epoch [1/1], Step [708/2252], Loss: 0.1993\n",
            "Epoch [1/1], Step [712/2252], Loss: 0.1896\n",
            "Epoch [1/1], Step [716/2252], Loss: 0.2805\n",
            "Epoch [1/1], Step [720/2252], Loss: 0.2251\n",
            "Epoch [1/1], Step [724/2252], Loss: 0.2169\n",
            "Epoch [1/1], Step [728/2252], Loss: 0.2328\n",
            "Epoch [1/1], Step [732/2252], Loss: 0.1587\n",
            "Epoch [1/1], Step [736/2252], Loss: 0.2321\n",
            "Epoch [1/1], Step [740/2252], Loss: 0.3271\n",
            "Epoch [1/1], Step [744/2252], Loss: 0.1373\n",
            "Epoch [1/1], Step [748/2252], Loss: 0.1434\n",
            "Epoch [1/1], Step [752/2252], Loss: 0.1538\n",
            "Epoch [1/1], Step [756/2252], Loss: 0.3132\n",
            "Epoch [1/1], Step [760/2252], Loss: 0.1492\n",
            "Epoch [1/1], Step [764/2252], Loss: 0.1558\n",
            "Epoch [1/1], Step [768/2252], Loss: 0.2658\n",
            "Epoch [1/1], Step [772/2252], Loss: 0.1141\n",
            "Epoch [1/1], Step [776/2252], Loss: 0.2224\n",
            "Epoch [1/1], Step [780/2252], Loss: 0.1847\n",
            "Epoch [1/1], Step [784/2252], Loss: 0.2294\n",
            "Epoch [1/1], Step [788/2252], Loss: 0.1954\n",
            "Epoch [1/1], Step [792/2252], Loss: 0.1473\n",
            "Epoch [1/1], Step [796/2252], Loss: 0.1121\n",
            "Epoch [1/1], Step [800/2252], Loss: 0.1661\n",
            "Epoch [1/1], Step [804/2252], Loss: 0.1509\n",
            "Epoch [1/1], Step [808/2252], Loss: 0.2386\n",
            "Epoch [1/1], Step [812/2252], Loss: 0.2102\n",
            "Epoch [1/1], Step [816/2252], Loss: 0.1154\n",
            "Epoch [1/1], Step [820/2252], Loss: 0.2868\n",
            "Epoch [1/1], Step [824/2252], Loss: 0.2219\n",
            "Epoch [1/1], Step [828/2252], Loss: 0.1881\n",
            "Epoch [1/1], Step [832/2252], Loss: 0.1654\n",
            "Epoch [1/1], Step [836/2252], Loss: 0.2190\n",
            "Epoch [1/1], Step [840/2252], Loss: 0.1204\n",
            "Epoch [1/1], Step [844/2252], Loss: 0.1126\n",
            "Epoch [1/1], Step [848/2252], Loss: 0.2285\n",
            "Epoch [1/1], Step [852/2252], Loss: 0.2239\n",
            "Epoch [1/1], Step [856/2252], Loss: 0.3322\n",
            "Epoch [1/1], Step [860/2252], Loss: 0.2736\n",
            "Epoch [1/1], Step [864/2252], Loss: 0.2178\n",
            "Epoch [1/1], Step [868/2252], Loss: 0.1861\n",
            "Epoch [1/1], Step [872/2252], Loss: 0.2743\n",
            "Epoch [1/1], Step [876/2252], Loss: 0.2205\n",
            "Epoch [1/1], Step [880/2252], Loss: 0.2304\n",
            "Epoch [1/1], Step [884/2252], Loss: 0.1919\n",
            "Epoch [1/1], Step [888/2252], Loss: 0.1982\n",
            "Epoch [1/1], Step [892/2252], Loss: 0.1704\n",
            "Epoch [1/1], Step [896/2252], Loss: 0.1771\n",
            "Epoch [1/1], Step [900/2252], Loss: 0.1786\n",
            "Epoch [1/1], Step [904/2252], Loss: 0.2603\n",
            "Epoch [1/1], Step [908/2252], Loss: 0.1808\n",
            "Epoch [1/1], Step [912/2252], Loss: 0.1711\n",
            "Epoch [1/1], Step [916/2252], Loss: 0.1204\n",
            "Epoch [1/1], Step [920/2252], Loss: 0.0821\n",
            "Epoch [1/1], Step [924/2252], Loss: 0.3973\n",
            "Epoch [1/1], Step [928/2252], Loss: 0.1944\n",
            "Epoch [1/1], Step [932/2252], Loss: 0.2226\n",
            "Epoch [1/1], Step [936/2252], Loss: 0.1256\n",
            "Epoch [1/1], Step [940/2252], Loss: 0.1556\n",
            "Epoch [1/1], Step [944/2252], Loss: 0.1477\n",
            "Epoch [1/1], Step [948/2252], Loss: 0.2300\n",
            "Epoch [1/1], Step [952/2252], Loss: 0.2520\n",
            "Epoch [1/1], Step [956/2252], Loss: 0.1733\n",
            "Epoch [1/1], Step [960/2252], Loss: 0.2022\n",
            "Epoch [1/1], Step [964/2252], Loss: 0.2245\n",
            "Epoch [1/1], Step [968/2252], Loss: 0.3344\n",
            "Epoch [1/1], Step [972/2252], Loss: 0.1553\n",
            "Epoch [1/1], Step [976/2252], Loss: 0.2043\n",
            "Epoch [1/1], Step [980/2252], Loss: 0.1573\n",
            "Epoch [1/1], Step [984/2252], Loss: 0.2210\n",
            "Epoch [1/1], Step [988/2252], Loss: 0.2798\n",
            "Epoch [1/1], Step [992/2252], Loss: 0.1991\n",
            "Epoch [1/1], Step [996/2252], Loss: 0.0963\n",
            "Epoch [1/1], Step [1000/2252], Loss: 0.1822\n",
            "Epoch [1/1], Step [1004/2252], Loss: 0.2301\n",
            "Epoch [1/1], Step [1008/2252], Loss: 0.2357\n",
            "Epoch [1/1], Step [1012/2252], Loss: 0.1753\n",
            "Epoch [1/1], Step [1016/2252], Loss: 0.2073\n",
            "Epoch [1/1], Step [1020/2252], Loss: 0.1367\n",
            "Epoch [1/1], Step [1024/2252], Loss: 0.1311\n",
            "Epoch [1/1], Step [1028/2252], Loss: 0.1987\n",
            "Epoch [1/1], Step [1032/2252], Loss: 0.1415\n",
            "Epoch [1/1], Step [1036/2252], Loss: 0.1029\n",
            "Epoch [1/1], Step [1040/2252], Loss: 0.2219\n",
            "Epoch [1/1], Step [1044/2252], Loss: 0.2056\n",
            "Epoch [1/1], Step [1048/2252], Loss: 0.0830\n",
            "Epoch [1/1], Step [1052/2252], Loss: 0.1794\n",
            "Epoch [1/1], Step [1056/2252], Loss: 0.1725\n",
            "Epoch [1/1], Step [1060/2252], Loss: 0.1185\n",
            "Epoch [1/1], Step [1064/2252], Loss: 0.1470\n",
            "Epoch [1/1], Step [1068/2252], Loss: 0.2171\n",
            "Epoch [1/1], Step [1072/2252], Loss: 0.2306\n",
            "Epoch [1/1], Step [1076/2252], Loss: 0.1874\n",
            "Epoch [1/1], Step [1080/2252], Loss: 0.1664\n",
            "Epoch [1/1], Step [1084/2252], Loss: 0.1597\n",
            "Epoch [1/1], Step [1088/2252], Loss: 0.0757\n",
            "Epoch [1/1], Step [1092/2252], Loss: 0.2102\n",
            "Epoch [1/1], Step [1096/2252], Loss: 0.3707\n",
            "Epoch [1/1], Step [1100/2252], Loss: 0.1521\n",
            "Epoch [1/1], Step [1104/2252], Loss: 0.1539\n",
            "Epoch [1/1], Step [1108/2252], Loss: 0.1375\n",
            "Epoch [1/1], Step [1112/2252], Loss: 0.1341\n",
            "Epoch [1/1], Step [1116/2252], Loss: 0.1590\n",
            "Epoch [1/1], Step [1120/2252], Loss: 0.1999\n",
            "Epoch [1/1], Step [1124/2252], Loss: 0.3000\n",
            "Epoch [1/1], Step [1128/2252], Loss: 0.1521\n",
            "Epoch [1/1], Step [1132/2252], Loss: 0.1625\n",
            "Epoch [1/1], Step [1136/2252], Loss: 0.1831\n",
            "Epoch [1/1], Step [1140/2252], Loss: 0.2633\n",
            "Epoch [1/1], Step [1144/2252], Loss: 0.1051\n",
            "Epoch [1/1], Step [1148/2252], Loss: 0.1691\n",
            "Epoch [1/1], Step [1152/2252], Loss: 0.2852\n",
            "Epoch [1/1], Step [1156/2252], Loss: 0.1490\n",
            "Epoch [1/1], Step [1160/2252], Loss: 0.1671\n",
            "Epoch [1/1], Step [1164/2252], Loss: 0.2394\n",
            "Epoch [1/1], Step [1168/2252], Loss: 0.2763\n",
            "Epoch [1/1], Step [1172/2252], Loss: 0.1272\n",
            "Epoch [1/1], Step [1176/2252], Loss: 0.1233\n",
            "Epoch [1/1], Step [1180/2252], Loss: 0.1430\n",
            "Epoch [1/1], Step [1184/2252], Loss: 0.1565\n",
            "Epoch [1/1], Step [1188/2252], Loss: 0.1788\n",
            "Epoch [1/1], Step [1192/2252], Loss: 0.2217\n",
            "Epoch [1/1], Step [1196/2252], Loss: 0.0833\n",
            "Epoch [1/1], Step [1200/2252], Loss: 0.2563\n",
            "Epoch [1/1], Step [1204/2252], Loss: 0.1939\n",
            "Epoch [1/1], Step [1208/2252], Loss: 0.1271\n",
            "Epoch [1/1], Step [1212/2252], Loss: 0.1418\n",
            "Epoch [1/1], Step [1216/2252], Loss: 0.1118\n",
            "Epoch [1/1], Step [1220/2252], Loss: 0.1241\n",
            "Epoch [1/1], Step [1224/2252], Loss: 0.3132\n",
            "Epoch [1/1], Step [1228/2252], Loss: 0.2331\n",
            "Epoch [1/1], Step [1232/2252], Loss: 0.1937\n",
            "Epoch [1/1], Step [1236/2252], Loss: 0.2588\n",
            "Epoch [1/1], Step [1240/2252], Loss: 0.2125\n",
            "Epoch [1/1], Step [1244/2252], Loss: 0.1489\n",
            "Epoch [1/1], Step [1248/2252], Loss: 0.3449\n",
            "Epoch [1/1], Step [1252/2252], Loss: 0.1629\n",
            "Epoch [1/1], Step [1256/2252], Loss: 0.2014\n",
            "Epoch [1/1], Step [1260/2252], Loss: 0.2372\n",
            "Epoch [1/1], Step [1264/2252], Loss: 0.1689\n",
            "Epoch [1/1], Step [1268/2252], Loss: 0.1597\n",
            "Epoch [1/1], Step [1272/2252], Loss: 0.2001\n",
            "Epoch [1/1], Step [1276/2252], Loss: 0.1895\n",
            "Epoch [1/1], Step [1280/2252], Loss: 0.0919\n",
            "Epoch [1/1], Step [1284/2252], Loss: 0.1082\n",
            "Epoch [1/1], Step [1288/2252], Loss: 0.1715\n",
            "Epoch [1/1], Step [1292/2252], Loss: 0.1160\n",
            "Epoch [1/1], Step [1296/2252], Loss: 0.2290\n",
            "Epoch [1/1], Step [1300/2252], Loss: 0.1974\n",
            "Epoch [1/1], Step [1304/2252], Loss: 0.1316\n",
            "Epoch [1/1], Step [1308/2252], Loss: 0.1600\n",
            "Epoch [1/1], Step [1312/2252], Loss: 0.2111\n",
            "Epoch [1/1], Step [1316/2252], Loss: 0.0954\n",
            "Epoch [1/1], Step [1320/2252], Loss: 0.2197\n",
            "Epoch [1/1], Step [1324/2252], Loss: 0.2189\n",
            "Epoch [1/1], Step [1328/2252], Loss: 0.2206\n",
            "Epoch [1/1], Step [1332/2252], Loss: 0.2850\n",
            "Epoch [1/1], Step [1336/2252], Loss: 0.1722\n",
            "Epoch [1/1], Step [1340/2252], Loss: 0.1688\n",
            "Epoch [1/1], Step [1344/2252], Loss: 0.1971\n",
            "Epoch [1/1], Step [1348/2252], Loss: 0.1281\n",
            "Epoch [1/1], Step [1352/2252], Loss: 0.1806\n",
            "Epoch [1/1], Step [1356/2252], Loss: 0.1842\n",
            "Epoch [1/1], Step [1360/2252], Loss: 0.2288\n",
            "Epoch [1/1], Step [1364/2252], Loss: 0.1842\n",
            "Epoch [1/1], Step [1368/2252], Loss: 0.2089\n",
            "Epoch [1/1], Step [1372/2252], Loss: 0.1469\n",
            "Epoch [1/1], Step [1376/2252], Loss: 0.0830\n",
            "Epoch [1/1], Step [1380/2252], Loss: 0.1512\n",
            "Epoch [1/1], Step [1384/2252], Loss: 0.1494\n",
            "Epoch [1/1], Step [1388/2252], Loss: 0.1090\n",
            "Epoch [1/1], Step [1392/2252], Loss: 0.1260\n",
            "Epoch [1/1], Step [1396/2252], Loss: 0.1331\n",
            "Epoch [1/1], Step [1400/2252], Loss: 0.1168\n",
            "Epoch [1/1], Step [1404/2252], Loss: 0.1833\n",
            "Epoch [1/1], Step [1408/2252], Loss: 0.1571\n",
            "Epoch [1/1], Step [1412/2252], Loss: 0.2085\n",
            "Epoch [1/1], Step [1416/2252], Loss: 0.1956\n",
            "Epoch [1/1], Step [1420/2252], Loss: 0.1561\n",
            "Epoch [1/1], Step [1424/2252], Loss: 0.1599\n",
            "Epoch [1/1], Step [1428/2252], Loss: 0.2352\n",
            "Epoch [1/1], Step [1432/2252], Loss: 0.1867\n",
            "Epoch [1/1], Step [1436/2252], Loss: 0.1553\n",
            "Epoch [1/1], Step [1440/2252], Loss: 0.1701\n",
            "Epoch [1/1], Step [1444/2252], Loss: 0.1092\n",
            "Epoch [1/1], Step [1448/2252], Loss: 0.1381\n",
            "Epoch [1/1], Step [1452/2252], Loss: 0.1947\n",
            "Epoch [1/1], Step [1456/2252], Loss: 0.1843\n",
            "Epoch [1/1], Step [1460/2252], Loss: 0.3003\n",
            "Epoch [1/1], Step [1464/2252], Loss: 0.0873\n",
            "Epoch [1/1], Step [1468/2252], Loss: 0.1546\n",
            "Epoch [1/1], Step [1472/2252], Loss: 0.2757\n",
            "Epoch [1/1], Step [1476/2252], Loss: 0.1884\n",
            "Epoch [1/1], Step [1480/2252], Loss: 0.2284\n",
            "Epoch [1/1], Step [1484/2252], Loss: 0.1378\n",
            "Epoch [1/1], Step [1488/2252], Loss: 0.2095\n",
            "Epoch [1/1], Step [1492/2252], Loss: 0.1943\n",
            "Epoch [1/1], Step [1496/2252], Loss: 0.1954\n",
            "Epoch [1/1], Step [1500/2252], Loss: 0.0899\n",
            "Epoch [1/1], Step [1504/2252], Loss: 0.1285\n",
            "Epoch [1/1], Step [1508/2252], Loss: 0.2430\n",
            "Epoch [1/1], Step [1512/2252], Loss: 0.1331\n",
            "Epoch [1/1], Step [1516/2252], Loss: 0.1874\n",
            "Epoch [1/1], Step [1520/2252], Loss: 0.2053\n",
            "Epoch [1/1], Step [1524/2252], Loss: 0.1346\n",
            "Epoch [1/1], Step [1528/2252], Loss: 0.1713\n",
            "Epoch [1/1], Step [1532/2252], Loss: 0.2353\n",
            "Epoch [1/1], Step [1536/2252], Loss: 0.1439\n",
            "Epoch [1/1], Step [1540/2252], Loss: 0.1189\n",
            "Epoch [1/1], Step [1544/2252], Loss: 0.1314\n",
            "Epoch [1/1], Step [1548/2252], Loss: 0.1366\n",
            "Epoch [1/1], Step [1552/2252], Loss: 0.1442\n",
            "Epoch [1/1], Step [1556/2252], Loss: 0.1428\n",
            "Epoch [1/1], Step [1560/2252], Loss: 0.1481\n",
            "Epoch [1/1], Step [1564/2252], Loss: 0.1409\n",
            "Epoch [1/1], Step [1568/2252], Loss: 0.1560\n",
            "Epoch [1/1], Step [1572/2252], Loss: 0.1209\n",
            "Epoch [1/1], Step [1576/2252], Loss: 0.1395\n",
            "Epoch [1/1], Step [1580/2252], Loss: 0.2348\n",
            "Epoch [1/1], Step [1584/2252], Loss: 0.3302\n",
            "Epoch [1/1], Step [1588/2252], Loss: 0.1318\n",
            "Epoch [1/1], Step [1592/2252], Loss: 0.2209\n",
            "Epoch [1/1], Step [1596/2252], Loss: 0.1630\n",
            "Epoch [1/1], Step [1600/2252], Loss: 0.0747\n",
            "Epoch [1/1], Step [1604/2252], Loss: 0.1285\n",
            "Epoch [1/1], Step [1608/2252], Loss: 0.1091\n",
            "Epoch [1/1], Step [1612/2252], Loss: 0.2068\n",
            "Epoch [1/1], Step [1616/2252], Loss: 0.1334\n",
            "Epoch [1/1], Step [1620/2252], Loss: 0.1825\n",
            "Epoch [1/1], Step [1624/2252], Loss: 0.0874\n",
            "Epoch [1/1], Step [1628/2252], Loss: 0.0889\n",
            "Epoch [1/1], Step [1632/2252], Loss: 0.1994\n",
            "Epoch [1/1], Step [1636/2252], Loss: 0.2134\n",
            "Epoch [1/1], Step [1640/2252], Loss: 0.1715\n",
            "Epoch [1/1], Step [1644/2252], Loss: 0.1705\n",
            "Epoch [1/1], Step [1648/2252], Loss: 0.1797\n",
            "Epoch [1/1], Step [1652/2252], Loss: 0.0872\n",
            "Epoch [1/1], Step [1656/2252], Loss: 0.1428\n",
            "Epoch [1/1], Step [1660/2252], Loss: 0.1488\n",
            "Epoch [1/1], Step [1664/2252], Loss: 0.1287\n",
            "Epoch [1/1], Step [1668/2252], Loss: 0.0898\n",
            "Epoch [1/1], Step [1672/2252], Loss: 0.1972\n",
            "Epoch [1/1], Step [1676/2252], Loss: 0.1864\n",
            "Epoch [1/1], Step [1680/2252], Loss: 0.0773\n",
            "Epoch [1/1], Step [1684/2252], Loss: 0.1094\n",
            "Epoch [1/1], Step [1688/2252], Loss: 0.1968\n",
            "Epoch [1/1], Step [1692/2252], Loss: 0.1736\n",
            "Epoch [1/1], Step [1696/2252], Loss: 0.2177\n",
            "Epoch [1/1], Step [1700/2252], Loss: 0.1337\n",
            "Epoch [1/1], Step [1704/2252], Loss: 0.1975\n",
            "Epoch [1/1], Step [1708/2252], Loss: 0.1441\n",
            "Epoch [1/1], Step [1712/2252], Loss: 0.1252\n",
            "Epoch [1/1], Step [1716/2252], Loss: 0.1252\n",
            "Epoch [1/1], Step [1720/2252], Loss: 0.2269\n",
            "Epoch [1/1], Step [1724/2252], Loss: 0.1025\n",
            "Epoch [1/1], Step [1728/2252], Loss: 0.2120\n",
            "Epoch [1/1], Step [1732/2252], Loss: 0.1654\n",
            "Epoch [1/1], Step [1736/2252], Loss: 0.1517\n",
            "Epoch [1/1], Step [1740/2252], Loss: 0.1407\n",
            "Epoch [1/1], Step [1744/2252], Loss: 0.1790\n",
            "Epoch [1/1], Step [1748/2252], Loss: 0.1175\n",
            "Epoch [1/1], Step [1752/2252], Loss: 0.1534\n",
            "Epoch [1/1], Step [1756/2252], Loss: 0.1720\n",
            "Epoch [1/1], Step [1760/2252], Loss: 0.1650\n",
            "Epoch [1/1], Step [1764/2252], Loss: 0.2130\n",
            "Epoch [1/1], Step [1768/2252], Loss: 0.1356\n",
            "Epoch [1/1], Step [1772/2252], Loss: 0.1013\n",
            "Epoch [1/1], Step [1776/2252], Loss: 0.0833\n",
            "Epoch [1/1], Step [1780/2252], Loss: 0.1504\n",
            "Epoch [1/1], Step [1784/2252], Loss: 0.1902\n",
            "Epoch [1/1], Step [1788/2252], Loss: 0.3108\n",
            "Epoch [1/1], Step [1792/2252], Loss: 0.1205\n",
            "Epoch [1/1], Step [1796/2252], Loss: 0.2210\n",
            "Epoch [1/1], Step [1800/2252], Loss: 0.1475\n",
            "Epoch [1/1], Step [1804/2252], Loss: 0.0935\n",
            "Epoch [1/1], Step [1808/2252], Loss: 0.1203\n",
            "Epoch [1/1], Step [1812/2252], Loss: 0.1700\n",
            "Epoch [1/1], Step [1816/2252], Loss: 0.1184\n",
            "Epoch [1/1], Step [1820/2252], Loss: 0.2324\n",
            "Epoch [1/1], Step [1824/2252], Loss: 0.1654\n",
            "Epoch [1/1], Step [1828/2252], Loss: 0.1973\n",
            "Epoch [1/1], Step [1832/2252], Loss: 0.2623\n",
            "Epoch [1/1], Step [1836/2252], Loss: 0.1102\n",
            "Epoch [1/1], Step [1840/2252], Loss: 0.1394\n",
            "Epoch [1/1], Step [1844/2252], Loss: 0.1237\n",
            "Epoch [1/1], Step [1848/2252], Loss: 0.2214\n",
            "Epoch [1/1], Step [1852/2252], Loss: 0.1727\n",
            "Epoch [1/1], Step [1856/2252], Loss: 0.1378\n",
            "Epoch [1/1], Step [1860/2252], Loss: 0.1183\n",
            "Epoch [1/1], Step [1864/2252], Loss: 0.2481\n",
            "Epoch [1/1], Step [1868/2252], Loss: 0.1852\n",
            "Epoch [1/1], Step [1872/2252], Loss: 0.1471\n",
            "Epoch [1/1], Step [1876/2252], Loss: 0.1601\n",
            "Epoch [1/1], Step [1880/2252], Loss: 0.1269\n",
            "Epoch [1/1], Step [1884/2252], Loss: 0.1570\n",
            "Epoch [1/1], Step [1888/2252], Loss: 0.1384\n",
            "Epoch [1/1], Step [1892/2252], Loss: 0.1713\n",
            "Epoch [1/1], Step [1896/2252], Loss: 0.1001\n",
            "Epoch [1/1], Step [1900/2252], Loss: 0.1136\n",
            "Epoch [1/1], Step [1904/2252], Loss: 0.0978\n",
            "Epoch [1/1], Step [1908/2252], Loss: 0.2070\n",
            "Epoch [1/1], Step [1912/2252], Loss: 0.2244\n",
            "Epoch [1/1], Step [1916/2252], Loss: 0.1374\n",
            "Epoch [1/1], Step [1920/2252], Loss: 0.2377\n",
            "Epoch [1/1], Step [1924/2252], Loss: 0.1136\n",
            "Epoch [1/1], Step [1928/2252], Loss: 0.1017\n",
            "Epoch [1/1], Step [1932/2252], Loss: 0.1900\n",
            "Epoch [1/1], Step [1936/2252], Loss: 0.1212\n",
            "Epoch [1/1], Step [1940/2252], Loss: 0.2079\n",
            "Epoch [1/1], Step [1944/2252], Loss: 0.2676\n",
            "Epoch [1/1], Step [1948/2252], Loss: 0.1686\n",
            "Epoch [1/1], Step [1952/2252], Loss: 0.1936\n",
            "Epoch [1/1], Step [1956/2252], Loss: 0.2660\n",
            "Epoch [1/1], Step [1960/2252], Loss: 0.1614\n",
            "Epoch [1/1], Step [1964/2252], Loss: 0.1306\n",
            "Epoch [1/1], Step [1968/2252], Loss: 0.1104\n",
            "Epoch [1/1], Step [1972/2252], Loss: 0.1883\n",
            "Epoch [1/1], Step [1976/2252], Loss: 0.1655\n",
            "Epoch [1/1], Step [1980/2252], Loss: 0.1683\n",
            "Epoch [1/1], Step [1984/2252], Loss: 0.1369\n",
            "Epoch [1/1], Step [1988/2252], Loss: 0.1792\n",
            "Epoch [1/1], Step [1992/2252], Loss: 0.1713\n",
            "Epoch [1/1], Step [1996/2252], Loss: 0.2268\n",
            "Epoch [1/1], Step [2000/2252], Loss: 0.1462\n",
            "Epoch [1/1], Step [2004/2252], Loss: 0.1295\n",
            "Epoch [1/1], Step [2008/2252], Loss: 0.1406\n",
            "Epoch [1/1], Step [2012/2252], Loss: 0.1984\n",
            "Epoch [1/1], Step [2016/2252], Loss: 0.1034\n",
            "Epoch [1/1], Step [2020/2252], Loss: 0.0896\n",
            "Epoch [1/1], Step [2024/2252], Loss: 0.1190\n",
            "Epoch [1/1], Step [2028/2252], Loss: 0.1009\n",
            "Epoch [1/1], Step [2032/2252], Loss: 0.1237\n",
            "Epoch [1/1], Step [2036/2252], Loss: 0.2732\n",
            "Epoch [1/1], Step [2040/2252], Loss: 0.1633\n",
            "Epoch [1/1], Step [2044/2252], Loss: 0.2004\n",
            "Epoch [1/1], Step [2048/2252], Loss: 0.2350\n",
            "Epoch [1/1], Step [2052/2252], Loss: 0.0956\n",
            "Epoch [1/1], Step [2056/2252], Loss: 0.1703\n",
            "Epoch [1/1], Step [2060/2252], Loss: 0.1072\n",
            "Epoch [1/1], Step [2064/2252], Loss: 0.2349\n",
            "Epoch [1/1], Step [2068/2252], Loss: 0.1188\n",
            "Epoch [1/1], Step [2072/2252], Loss: 0.1989\n",
            "Epoch [1/1], Step [2076/2252], Loss: 0.2152\n",
            "Epoch [1/1], Step [2080/2252], Loss: 0.1865\n",
            "Epoch [1/1], Step [2084/2252], Loss: 0.2147\n",
            "Epoch [1/1], Step [2088/2252], Loss: 0.1683\n",
            "Epoch [1/1], Step [2092/2252], Loss: 0.1206\n",
            "Epoch [1/1], Step [2096/2252], Loss: 0.0843\n",
            "Epoch [1/1], Step [2100/2252], Loss: 0.1726\n",
            "Epoch [1/1], Step [2104/2252], Loss: 0.1465\n",
            "Epoch [1/1], Step [2108/2252], Loss: 0.1066\n",
            "Epoch [1/1], Step [2112/2252], Loss: 0.1105\n",
            "Epoch [1/1], Step [2116/2252], Loss: 0.0969\n",
            "Epoch [1/1], Step [2120/2252], Loss: 0.2081\n",
            "Epoch [1/1], Step [2124/2252], Loss: 0.0912\n",
            "Epoch [1/1], Step [2128/2252], Loss: 0.1588\n",
            "Epoch [1/1], Step [2132/2252], Loss: 0.1282\n",
            "Epoch [1/1], Step [2136/2252], Loss: 0.0839\n",
            "Epoch [1/1], Step [2140/2252], Loss: 0.1238\n",
            "Epoch [1/1], Step [2144/2252], Loss: 0.1947\n",
            "Epoch [1/1], Step [2148/2252], Loss: 0.2077\n",
            "Epoch [1/1], Step [2152/2252], Loss: 0.2033\n",
            "Epoch [1/1], Step [2156/2252], Loss: 0.1456\n",
            "Epoch [1/1], Step [2160/2252], Loss: 0.1910\n",
            "Epoch [1/1], Step [2164/2252], Loss: 0.1077\n",
            "Epoch [1/1], Step [2168/2252], Loss: 0.1473\n",
            "Epoch [1/1], Step [2172/2252], Loss: 0.2426\n",
            "Epoch [1/1], Step [2176/2252], Loss: 0.1112\n",
            "Epoch [1/1], Step [2180/2252], Loss: 0.0739\n",
            "Epoch [1/1], Step [2184/2252], Loss: 0.2298\n",
            "Epoch [1/1], Step [2188/2252], Loss: 0.1477\n",
            "Epoch [1/1], Step [2192/2252], Loss: 0.1075\n",
            "Epoch [1/1], Step [2196/2252], Loss: 0.1876\n",
            "Epoch [1/1], Step [2200/2252], Loss: 0.1871\n",
            "Epoch [1/1], Step [2204/2252], Loss: 0.2764\n",
            "Epoch [1/1], Step [2208/2252], Loss: 0.1798\n",
            "Epoch [1/1], Step [2212/2252], Loss: 0.1872\n",
            "Epoch [1/1], Step [2216/2252], Loss: 0.2394\n",
            "Epoch [1/1], Step [2220/2252], Loss: 0.1591\n",
            "Epoch [1/1], Step [2224/2252], Loss: 0.1860\n",
            "Epoch [1/1], Step [2228/2252], Loss: 0.1881\n",
            "Epoch [1/1], Step [2232/2252], Loss: 0.1801\n",
            "Epoch [1/1], Step [2236/2252], Loss: 0.1443\n",
            "Epoch [1/1], Step [2240/2252], Loss: 0.1589\n",
            "Epoch [1/1], Step [2244/2252], Loss: 0.2128\n",
            "Epoch [1/1], Step [2248/2252], Loss: 0.0931\n",
            "Epoch [1/1], Step [2252/2252], Loss: 0.1412\n",
            "Name---> layer_1.weight \n",
            "Values---> tensor([[ 1.6428e-01,  4.0393e-02,  1.5537e-01,  ...,  1.6893e-03,\n",
            "          1.1037e-03,  9.8744e-05],\n",
            "        [ 2.5255e-01, -6.5343e-02, -1.3858e-02,  ..., -2.0985e-03,\n",
            "          1.5639e-03, -2.4374e-04],\n",
            "        [-5.4354e-01, -1.5934e-01,  1.5624e-01,  ..., -2.4481e-03,\n",
            "         -1.9948e-03, -1.8415e-03],\n",
            "        ...,\n",
            "        [-4.7626e-01, -3.7353e-01, -8.6573e-02,  ..., -2.5514e-03,\n",
            "         -1.5191e-05,  1.8468e-03],\n",
            "        [ 9.6423e-02, -1.0953e-02,  3.7165e-02,  ...,  1.6966e-03,\n",
            "         -7.4708e-04,  2.0977e-03],\n",
            "        [-2.0210e-01, -1.7279e-01,  2.8285e-01,  ..., -1.7140e-03,\n",
            "          1.6422e-03, -1.8408e-03]], device='cuda:0')\n",
            "Name---> layer_1.bias \n",
            "Values---> tensor([-0.0185,  0.0040, -0.3824,  0.1719,  0.1378, -0.0797, -0.1096, -0.0425,\n",
            "        -0.0570, -0.0268, -0.2273, -0.3033, -0.2660, -0.2348, -0.0363, -0.3488,\n",
            "         0.0375, -0.4214, -0.0720, -0.2759, -0.2584, -0.2600,  0.1289, -0.6375,\n",
            "        -0.3765, -0.1466, -0.1746, -0.1477, -0.0643,  0.0450, -0.0862, -0.0068,\n",
            "        -0.4315, -0.0454, -0.1372, -0.0458, -0.0842,  0.0410, -0.6299, -0.2091,\n",
            "        -0.0976, -0.1409, -0.1633, -0.1004,  0.2458, -0.1352, -0.1108,  0.2523,\n",
            "         0.0413,  0.0048,  0.2056, -0.0658, -0.1276, -0.3661, -0.5623,  0.0127,\n",
            "        -0.1742, -0.1786,  0.0794,  0.1783, -0.0761, -0.0857, -0.1644, -0.4508,\n",
            "        -0.2312, -0.2508,  0.0952,  0.0140, -0.1065, -0.0850,  0.1056, -0.1076,\n",
            "         0.2200,  0.0748, -0.2723, -0.1334, -0.3824, -0.4577, -0.2742,  0.0343,\n",
            "        -0.3751, -0.1317, -0.3840, -0.4266, -0.1391, -0.1469, -0.2474, -0.1048,\n",
            "        -0.0837, -0.2203,  0.0468,  0.0990, -0.1239,  0.1998,  0.1111, -0.0253,\n",
            "         0.0024,  0.1370, -0.0011, -0.2982], device='cuda:0')\n",
            "Name---> layer_2.weight \n",
            "Values---> tensor([[-0.0733,  0.0971, -0.2489,  ..., -0.6994, -0.1178, -0.0314],\n",
            "        [-0.0919, -0.2567, -0.0145,  ..., -0.0899, -0.2497, -0.0207],\n",
            "        [-0.2707, -0.5285, -0.2438,  ..., -0.3489, -0.6921, -0.0687],\n",
            "        ...,\n",
            "        [-0.3585, -0.3936,  0.0046,  ...,  0.0735, -0.3826,  0.0924],\n",
            "        [-0.1885,  0.2691,  0.2551,  ..., -0.0378, -0.1854,  0.4728],\n",
            "        [-0.0374, -0.0274,  0.0058,  ..., -0.1476, -0.1135, -0.0721]],\n",
            "       device='cuda:0')\n",
            "Name---> layer_2.bias \n",
            "Values---> tensor([ 2.8850e-01, -2.6683e-01, -1.6077e-01,  6.6864e-01, -3.6291e-01,\n",
            "         6.0914e-01,  1.8193e-02, -4.4445e-02, -9.7036e-02, -2.1489e-01,\n",
            "         7.0947e-01, -7.7788e-03, -7.6706e-04, -6.5627e-02, -1.0048e-01,\n",
            "         4.2547e-01,  1.2591e-01,  1.8927e-01,  6.5689e-01,  8.2536e-02,\n",
            "        -3.0762e-01,  8.9856e-01,  5.2530e-01, -1.5276e-01,  1.7258e-01,\n",
            "        -5.1150e-03,  9.4073e-02,  3.4208e-03,  7.6147e-01, -9.7667e-02,\n",
            "         3.2998e-02, -9.2326e-02, -1.6427e-01, -1.9455e-01, -9.0431e-02,\n",
            "        -8.1025e-02,  1.5377e-01,  1.1663e-01, -1.3253e-01,  2.0708e-01,\n",
            "        -3.0772e-02,  6.2554e-01, -4.8686e-02,  3.7466e-01, -6.9380e-01,\n",
            "         6.0370e-01, -1.5890e-01, -1.6684e-01,  5.3486e-03, -1.8485e-01,\n",
            "         3.3798e-01,  8.4460e-03, -1.1024e-01, -1.6951e-02, -7.9293e-02,\n",
            "        -8.6098e-02,  3.0219e-02, -1.3542e-02,  2.5875e-01, -2.7229e-01,\n",
            "        -1.4663e-01,  1.2511e-01,  2.1866e-01, -2.3649e-01,  4.4713e-02,\n",
            "         5.1089e-01,  7.9789e-03,  6.8503e-01, -6.1060e-02, -4.5377e-02,\n",
            "         3.3522e-01, -1.2300e-01,  7.9171e-02, -4.2518e-02, -9.7639e-02,\n",
            "         8.5627e-02, -2.9387e-01, -1.7946e-01, -2.6915e-01,  3.4540e-01,\n",
            "        -1.0738e-01,  4.4406e-02,  5.6359e-01,  1.6773e-01,  3.4532e-01,\n",
            "         3.5715e-01,  1.0136e+00,  1.1366e-01, -9.0307e-02, -8.9657e-02,\n",
            "         5.3769e-02,  1.1916e-01, -1.4971e-01,  7.0027e-02,  1.9628e-01,\n",
            "        -8.2560e-02,  9.4376e-01,  1.0509e-01,  3.4798e-02, -9.5897e-02],\n",
            "       device='cuda:0')\n",
            "Name---> output_layer.weight \n",
            "Values---> tensor([[ 6.7638e-02,  9.7919e-02, -5.4820e-01, -1.1139e-01, -1.6154e-01,\n",
            "          4.3727e-02,  9.6365e-03,  8.9988e-02,  8.7516e-02,  6.9127e-02,\n",
            "          2.2942e-01,  7.6590e-02,  1.5337e-02,  5.5698e-02,  2.1269e-02,\n",
            "          3.4643e-02,  3.3773e-02, -8.4714e-02, -1.1209e-01,  7.3166e-02,\n",
            "         -9.2150e-02,  1.9064e-01,  4.9583e-02,  1.0293e-01,  6.1743e-02,\n",
            "          4.0391e-02, -2.0351e-02,  2.7704e-02, -1.6539e-01, -2.0340e-01,\n",
            "          1.1871e-01,  1.1576e-01,  3.3142e-02, -5.0877e-02,  1.4971e-01,\n",
            "          4.4337e-02,  8.4751e-03,  1.6005e-01,  4.5744e-02,  1.7234e-01,\n",
            "         -9.2744e-02,  1.1174e-01, -9.1098e-02, -1.8005e-02, -1.8668e-01,\n",
            "          1.9598e-01,  1.2736e-02,  2.6874e-01, -9.7087e-02, -5.2690e-03,\n",
            "         -6.8062e-02, -1.1166e-01,  7.0174e-03, -8.7981e-04, -1.5318e-01,\n",
            "          2.0911e-01, -7.3916e-02,  7.6508e-02, -3.0054e-02,  1.8925e-01,\n",
            "         -7.2659e-02, -6.4446e-02,  1.2137e-01,  2.4087e-01,  1.2042e-01,\n",
            "         -4.9157e-02, -1.1808e-01, -6.1612e-02, -3.9982e-02, -1.6676e-01,\n",
            "          2.7641e-02, -4.8763e-02,  1.1309e-01, -1.5827e-01,  4.4252e-02,\n",
            "          1.3771e-01,  9.7529e-02, -5.1201e-02, -5.9203e-02, -1.3486e-02,\n",
            "         -9.0652e-02, -6.7618e-03, -2.3998e-01, -1.5912e-01,  1.6126e-01,\n",
            "          8.1179e-02, -1.7097e-01,  4.1433e-03,  1.9966e-02, -1.0010e-01,\n",
            "          6.1794e-02, -2.7177e-02, -8.9982e-02,  3.9508e-03,  4.6933e-02,\n",
            "         -1.3068e-01, -1.6317e-01,  7.0117e-03, -8.6091e-02, -7.4759e-02],\n",
            "        [ 5.9247e-03, -2.1359e-01, -9.4228e-03, -8.6580e-02, -1.4592e-01,\n",
            "          2.1929e-02,  1.2420e-01, -1.3655e-02, -6.7919e-02,  1.1478e-01,\n",
            "          1.7478e-01, -1.7682e-01,  9.1720e-02,  1.1422e-02,  8.8593e-02,\n",
            "         -1.1342e-01, -1.1890e-01,  2.2818e-01,  1.2423e-01,  9.1596e-02,\n",
            "          2.1882e-01, -1.6811e-01,  2.4174e-02, -1.9753e-02, -1.7944e-02,\n",
            "          5.6620e-02,  1.0447e-02,  5.7476e-02,  2.5495e-01, -8.7807e-02,\n",
            "          9.5997e-02,  8.2030e-02, -2.7492e-03,  7.0003e-02, -4.6648e-02,\n",
            "         -3.5710e-02,  8.8471e-02,  1.5667e-01, -1.3335e-01,  1.3344e-01,\n",
            "          9.6931e-02, -1.2356e-01, -1.5643e-02, -1.1877e-01, -6.7953e-03,\n",
            "         -1.1183e-01,  6.1251e-02, -2.2539e-01, -3.1995e-02, -9.7367e-02,\n",
            "         -8.8842e-02,  1.3700e-01, -6.1496e-02,  7.3823e-02,  1.1857e-01,\n",
            "         -1.4108e-01,  1.0950e-01,  1.3371e-02,  4.3179e-02, -2.2576e-01,\n",
            "         -4.4862e-02,  1.3209e-01,  8.0127e-02, -2.6820e-01, -1.5362e-01,\n",
            "          1.2161e-01, -9.1866e-02,  9.8343e-02, -1.4178e-01, -1.3043e-01,\n",
            "         -2.4335e-02,  9.8511e-02,  1.0392e-01,  6.4300e-02, -8.7823e-02,\n",
            "          1.6744e-01, -5.4668e-02, -6.2738e-02, -5.6619e-02, -1.0536e-01,\n",
            "          4.1850e-02,  3.9861e-02, -2.5287e-01, -3.0254e-02,  1.3819e-01,\n",
            "         -1.5740e-01,  8.5921e-02,  6.2182e-02, -7.8195e-02, -7.4786e-02,\n",
            "          5.8010e-02,  5.8944e-02,  4.7637e-02,  1.3442e-01,  2.0508e-02,\n",
            "         -1.1317e-01, -1.6771e-01,  6.0724e-02, -1.0742e-01,  5.2107e-02],\n",
            "        [ 2.2413e-02, -2.1394e-01,  1.7302e-01,  1.3876e-01, -3.6873e-02,\n",
            "          1.1783e-01,  1.4891e-01,  1.0408e-01,  6.4479e-02, -9.0963e-02,\n",
            "         -3.6816e-01,  2.8144e-02, -2.7256e-02,  1.2067e-01,  1.7692e-02,\n",
            "         -1.1026e-01,  3.2226e-02,  1.2866e-01, -1.6954e-01,  1.3880e-01,\n",
            "         -2.9765e-01,  8.9794e-02, -1.9253e-01, -1.8944e-03, -1.5322e-01,\n",
            "          5.4132e-02,  4.3002e-02,  4.0523e-02, -6.2782e-02, -6.7951e-02,\n",
            "          3.4869e-02,  4.0452e-02,  4.0802e-02,  1.8424e-03,  9.5618e-02,\n",
            "          8.8210e-02, -1.0348e-01, -2.2148e-01, -6.7077e-02, -2.1451e-01,\n",
            "          2.8873e-02, -1.7632e-01,  1.0072e-01,  1.2213e-01, -2.6100e-02,\n",
            "         -1.8425e-01, -9.7403e-02, -3.1697e-01, -5.8073e-04,  1.7015e-01,\n",
            "          2.4501e-02,  6.2015e-02, -9.7182e-03,  5.3984e-02,  1.5064e-02,\n",
            "         -1.9542e-01, -1.1737e-03,  4.0199e-02,  1.0048e-01, -8.0182e-03,\n",
            "          4.7034e-03,  1.4885e-01,  1.2088e-01, -1.9731e-01, -1.3421e-01,\n",
            "         -3.2465e-01,  1.2434e-01,  1.2576e-01, -1.4527e-01,  8.1671e-02,\n",
            "          6.6184e-02,  2.6126e-02,  1.3868e-02,  4.6130e-02,  2.3782e-02,\n",
            "         -3.2185e-01,  1.1768e-01,  1.3150e-01, -1.5141e-02, -3.1084e-01,\n",
            "         -2.2613e-02, -5.0377e-02, -1.5028e-01,  7.8194e-02, -2.3908e-01,\n",
            "         -2.1232e-01,  1.3719e-01,  8.7433e-02,  4.5287e-02, -3.5854e-02,\n",
            "          5.0319e-02,  1.7249e-02,  1.9444e-02,  9.7651e-02,  4.3803e-02,\n",
            "         -4.5853e-02,  2.8881e-01, -2.4216e-01, -3.1164e-01,  1.8117e-03],\n",
            "        [-4.0131e-01, -5.6040e-02, -5.0457e-01,  9.5348e-02,  2.5440e-02,\n",
            "         -1.1630e-01, -5.6969e-02, -6.2778e-03, -3.7211e-02, -1.3118e-01,\n",
            "         -3.0918e-01,  1.2802e-02,  6.3918e-02, -2.0775e-02,  5.0826e-02,\n",
            "          7.3246e-02,  6.3896e-02, -4.3735e-02,  1.7362e-01, -1.7010e-01,\n",
            "          5.0256e-02, -1.7623e-01,  6.0855e-02, -1.5699e-02,  7.3243e-02,\n",
            "         -6.6821e-02, -1.5461e-02, -1.1281e-01, -8.7587e-02,  2.1862e-02,\n",
            "         -6.0434e-03, -5.6556e-02, -2.2919e-02, -3.2781e-02, -4.3134e-02,\n",
            "         -1.0975e-01,  5.3914e-02, -2.8528e-01, -8.3627e-02,  1.9762e-02,\n",
            "         -3.7116e-02,  1.1629e-01, -2.9567e-02,  6.8617e-03,  3.9228e-02,\n",
            "          4.8064e-02, -1.3255e-02, -3.3131e-01, -1.1688e-01, -9.8433e-02,\n",
            "          1.0973e-01,  1.1681e-03, -1.1251e-01, -4.7488e-02,  8.8251e-02,\n",
            "         -1.9785e-01, -2.9851e-02,  5.6826e-02,  9.5314e-02, -3.1380e-01,\n",
            "         -3.4482e-03, -1.2675e-03, -2.6177e-01, -2.5526e-01,  9.3120e-02,\n",
            "          1.9567e-01, -7.4162e-02, -5.1839e-02, -7.8767e-02,  2.1585e-02,\n",
            "          3.1267e-02,  1.8533e-02, -6.4398e-02, -6.0615e-02, -8.9410e-02,\n",
            "         -1.6362e-01, -1.7480e-01, -1.4903e-01,  1.0491e-01,  7.4947e-02,\n",
            "         -3.9004e-02,  6.5843e-02,  3.1764e-01,  1.1132e-01, -1.6763e-01,\n",
            "          5.8569e-02, -2.5049e-01, -1.1257e-01, -2.8911e-03, -1.4150e-01,\n",
            "          4.5561e-04,  4.3030e-02, -1.3368e-01, -6.9768e-02,  6.2844e-02,\n",
            "          1.9890e-02, -5.1941e-02,  5.8991e-02, -4.2095e-02, -5.4393e-02]],\n",
            "       device='cuda:0')\n",
            "Name---> output_layer.bias \n",
            "Values---> tensor([ 0.2077,  0.1059,  0.1328, -0.4384], device='cuda:0')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           b       0.92      0.94      0.93     23183\n",
            "           t       0.94      0.92      0.93     21663\n",
            "           e       0.97      0.97      0.97     30482\n",
            "           m       0.94      0.93      0.94      9122\n",
            "\n",
            "    accuracy                           0.95     84450\n",
            "   macro avg       0.94      0.94      0.94     84450\n",
            "weighted avg       0.95      0.95      0.95     84450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# used code from lecture notebook but exchanged the data\n",
        "vocab = Counter()\n",
        "for text in training_data[\"TITLE\"]:\n",
        "    for word in text.split(\" \"):\n",
        "        vocab[word.lower()] += 1\n",
        "\n",
        "for text in testing_data[\"TITLE\"]:\n",
        "    for word in text.split(\" \"):\n",
        "        vocab[word.lower()] += 1\n",
        "\n",
        "total_words = len(vocab)\n",
        "\n",
        "\n",
        "def get_word_2_index(vocab):\n",
        "    word2index = {}\n",
        "    for i, word in enumerate(vocab):\n",
        "        word2index[word.lower()] = i\n",
        "    return word2index\n",
        "\n",
        "\n",
        "word2index = get_word_2_index(vocab)\n",
        "\n",
        "\n",
        "def get_batch(df, i, batch_size):\n",
        "    batches = []\n",
        "    results = []\n",
        "\n",
        "    # used iloc from pandas package because working with dataframe not array\n",
        "    # extracting batch of data from dataframe\n",
        "    texts = df[\"TITLE\"].iloc[i * batch_size : i * batch_size + batch_size]\n",
        "    categories = df[\"CATEGORY\"].iloc[i * batch_size : i * batch_size + batch_size]\n",
        "\n",
        "    for text in texts:\n",
        "        layer = np.zeros(total_words, dtype=float)\n",
        "        for word in text.split(\" \"):\n",
        "            layer[word2index[word.lower()]] += 1\n",
        "        batches.append(layer)\n",
        "\n",
        "    # convert categories to numbers\n",
        "    for category in categories:\n",
        "        index_y = -1\n",
        "        if category == \"b\":\n",
        "            index_y = 0\n",
        "        elif category == \"t\":\n",
        "            index_y = 1\n",
        "        elif category == \"e\":\n",
        "            index_y = 2\n",
        "        elif category == \"m\":\n",
        "            index_y = 3\n",
        "        results.append(index_y)\n",
        "\n",
        "    return np.array(batches), np.array(results)\n",
        "\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.01\n",
        "num_epochs = (\n",
        "    1  # changed epoch size so training is faster, you can increase it if you want\n",
        ")\n",
        "batch_size = 150\n",
        "display_step = 1\n",
        "\n",
        "# Network Parameters\n",
        "hidden_size = 100  # 1st layer and 2nd layer number of feature\n",
        "input_size = total_words  # Words in vocab\n",
        "num_classes = 4\n",
        "\n",
        "# select gpu (cuda) as method for faster training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Verwendetes Gerät:\", device)\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.empty_cache()  # empty cache -> otherwise there were sometimes errors\n",
        "\n",
        "\n",
        "class NewsNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NewsNN, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_size, hidden_size, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer_2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
        "        self.output_layer = nn.Linear(hidden_size, num_classes, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer_1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer_2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.output_layer(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# with \"to()\" you can easily switch between CPU and GPU without changing the rest of your code\n",
        "# had some problems with it so we added it\n",
        "news_net = NewsNN(input_size, hidden_size, num_classes).to(device)\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # This includes the Softmax loss function\n",
        "optimizer = torch.optim.Adam(news_net.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the Model\n",
        "for epoch in range(num_epochs):\n",
        "    # determine the number of min-batches based on the batch size and size of training data - exchanged the data\n",
        "    total_batch = int(len(training_data) / batch_size)\n",
        "    # Loop over all batches\n",
        "    for i in range(total_batch):\n",
        "        batch_x, batch_y = get_batch(training_data, i, batch_size)\n",
        "        articles = torch.FloatTensor(batch_x).to(device)\n",
        "        labels = torch.LongTensor(batch_y).to(device)\n",
        "        # print(\"articles\",articles)\n",
        "        # print(batch_x, labels)\n",
        "        # print(\"size labels\",labels.size())\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()  # zero the gradient buffer\n",
        "        outputs = news_net(articles)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 4 == 0:\n",
        "            print(\n",
        "                \"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\"\n",
        "                % (\n",
        "                    epoch + 1,\n",
        "                    num_epochs,\n",
        "                    i + 1,\n",
        "                    len(training_data) / batch_size,\n",
        "                    loss.data,\n",
        "                )\n",
        "            )\n",
        "\n",
        "# show the different trained parameters\n",
        "for name, param in news_net.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(\"Name--->\", name, \"\\nValues--->\", param.data)\n",
        "\n",
        "# set model to evaluation mode\n",
        "news_net.eval()\n",
        "total_test_batches = int(len(testing_data) / batch_size)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # create empty result arrays\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "    # iterate through each of the batches\n",
        "    for i in range(total_test_batches):\n",
        "        # get data of corresponding batch\n",
        "        test_batch_x, test_batch_y = get_batch(testing_data, i, batch_size)\n",
        "        test_articles = torch.FloatTensor(test_batch_x).to(device)\n",
        "        test_labels = torch.LongTensor(test_batch_y).to(device)\n",
        "        # get data into NN and get predicted labels\n",
        "        test_outputs = news_net(test_articles)\n",
        "        _, predicted = torch.max(test_outputs.data, 1)\n",
        "        \n",
        "        # we need .cpu() because we did .to(device) which was mainly gpu\n",
        "        all_predicted.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(test_labels.cpu().numpy())\n",
        "\n",
        "# print / create classification report for the predicted data\n",
        "print(\n",
        "    classification_report(all_labels, all_predicted, target_names=[\"b\", \"t\", \"e\", \"m\"])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjjpDsBbr-jS"
      },
      "source": [
        "# Task 4\n",
        "\n",
        "Use a pre-trained embeddings and compare your result. When you use pre-trained\n",
        "embeddings, you have to average the word embeddings of each tokens in ach\n",
        "document to get the unique representation of the document. DOC_EMBEDDING =\n",
        "(TOKEN1_EMBEDDING + ... + TOKENn_EMBEDDING). You can also use some of the\n",
        "spacy/FLAIR document embedding methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1SX6SR5j-kj"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Network Parameters\n",
        "hidden_size = 100  # 1st layer and 2nd layer number of feature\n",
        "input_size = total_words  # Words in vocab\n",
        "\n",
        "# Set hyperparameters\n",
        "embedding_dim = 300  # SpaCy provides 300-dimensional word vectors\n",
        "num_classes = 4\n",
        "hidden_dim = 100\n",
        "num_epochs = 1\n",
        "batch_size = 150\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Tokenization and embeddings using spacy with the larger English model\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "\n",
        "\n",
        "def calculate_average_embedding(text):\n",
        "    doc = nlp(text)\n",
        "    # Use the vector attribute to get the word vectors\n",
        "    embeddings = [token.vector for token in doc]\n",
        "    if embeddings:\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    else:\n",
        "        return np.zeros(embedding_dim)\n",
        "\n",
        "\n",
        "# Apply tokenization and embeddings to the dataset\n",
        "training_data[\"SPACY_EMBEDDING\"] = training_data[\"TITLE\"].apply(\n",
        "    calculate_average_embedding\n",
        ")\n",
        "testing_data[\"SPACY_EMBEDDING\"] = testing_data[\"TITLE\"].apply(\n",
        "    calculate_average_embedding\n",
        ")\n",
        "\n",
        "# Convert embeddings to torch tensors\n",
        "train_embeddings = torch.tensor(np.vstack(training_data[\"SPACY_EMBEDDING\"].to_numpy()))\n",
        "test_embeddings = torch.tensor(np.vstack(testing_data[\"SPACY_EMBEDDING\"].to_numpy()))\n",
        "\n",
        "label_mapping = {\"b\": 0, \"t\": 1, \"e\": 2, \"m\": 3}\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(training_data[\"CATEGORY\"].map(label_mapping).to_numpy())\n",
        "test_labels = torch.tensor(testing_data[\"CATEGORY\"].map(label_mapping).to_numpy())\n",
        "\n",
        "# Instantiate the model\n",
        "model = NewsNN(embedding_dim, hidden_dim, num_classes)\n",
        "\n",
        "# Loss and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(train_embeddings), batch_size):\n",
        "        inputs = train_embeddings[i : i + batch_size]\n",
        "        labels = train_labels[i : i + batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.float())\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if ((i // batch_size) + 1) % 2 == 0:\n",
        "            print(\n",
        "                \"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\"\n",
        "                % (\n",
        "                    epoch + 1,\n",
        "                    num_epochs,\n",
        "                    i // batch_size,\n",
        "                    len(train_embeddings) // batch_size,\n",
        "                    loss.data,\n",
        "                )\n",
        "            )\n",
        "\n",
        "# Evaluate on the test set\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(test_embeddings.float())\n",
        "    _, test_predictions = torch.max(test_outputs, 1)\n",
        "\n",
        "test_predictions = test_predictions.numpy()\n",
        "test_labels = test_labels.numpy()\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels, test_predictions, target_names=label_mapping))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HpuGterpBQs",
        "outputId": "e3a50d8d-fc1b-4e19-b502-34b4d1275859"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:46, 5.19MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [01:02<00:00, 6414.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [1/112], Loss: 1.2954\n",
            "Epoch [1/1], Step [3/112], Loss: 1.1915\n",
            "Epoch [1/1], Step [5/112], Loss: 1.1502\n",
            "Epoch [1/1], Step [7/112], Loss: 1.0810\n",
            "Epoch [1/1], Step [9/112], Loss: 1.0278\n",
            "Epoch [1/1], Step [11/112], Loss: 1.0270\n",
            "Epoch [1/1], Step [13/112], Loss: 0.9577\n",
            "Epoch [1/1], Step [15/112], Loss: 0.9733\n",
            "Epoch [1/1], Step [17/112], Loss: 0.9294\n",
            "Epoch [1/1], Step [19/112], Loss: 0.9462\n",
            "Epoch [1/1], Step [21/112], Loss: 0.9344\n",
            "Epoch [1/1], Step [23/112], Loss: 0.9276\n",
            "Epoch [1/1], Step [25/112], Loss: 0.9029\n",
            "Epoch [1/1], Step [27/112], Loss: 0.9286\n",
            "Epoch [1/1], Step [29/112], Loss: 0.8933\n",
            "Epoch [1/1], Step [31/112], Loss: 0.8681\n",
            "Epoch [1/1], Step [33/112], Loss: 0.8798\n",
            "Epoch [1/1], Step [35/112], Loss: 0.8652\n",
            "Epoch [1/1], Step [37/112], Loss: 0.8738\n",
            "Epoch [1/1], Step [39/112], Loss: 0.8865\n",
            "Epoch [1/1], Step [41/112], Loss: 0.8775\n",
            "Epoch [1/1], Step [43/112], Loss: 0.8639\n",
            "Epoch [1/1], Step [45/112], Loss: 0.8455\n",
            "Epoch [1/1], Step [47/112], Loss: 0.8664\n",
            "Epoch [1/1], Step [49/112], Loss: 0.8579\n",
            "Epoch [1/1], Step [51/112], Loss: 0.8609\n",
            "Epoch [1/1], Step [53/112], Loss: 0.8387\n",
            "Epoch [1/1], Step [55/112], Loss: 0.8346\n",
            "Epoch [1/1], Step [57/112], Loss: 0.8604\n",
            "Epoch [1/1], Step [59/112], Loss: 0.8467\n",
            "Epoch [1/1], Step [61/112], Loss: 0.8499\n",
            "Epoch [1/1], Step [63/112], Loss: 0.8277\n",
            "Epoch [1/1], Step [65/112], Loss: 0.8458\n",
            "Epoch [1/1], Step [67/112], Loss: 0.8411\n",
            "Epoch [1/1], Step [69/112], Loss: 0.8300\n",
            "Epoch [1/1], Step [71/112], Loss: 0.8782\n",
            "Epoch [1/1], Step [73/112], Loss: 0.8321\n",
            "Epoch [1/1], Step [75/112], Loss: 0.8658\n",
            "Epoch [1/1], Step [77/112], Loss: 0.8340\n",
            "Epoch [1/1], Step [79/112], Loss: 0.8311\n",
            "Epoch [1/1], Step [81/112], Loss: 0.8572\n",
            "Epoch [1/1], Step [83/112], Loss: 0.8077\n",
            "Epoch [1/1], Step [85/112], Loss: 0.8148\n",
            "Epoch [1/1], Step [87/112], Loss: 0.8283\n",
            "Epoch [1/1], Step [89/112], Loss: 0.8068\n",
            "Epoch [1/1], Step [91/112], Loss: 0.8340\n",
            "Epoch [1/1], Step [93/112], Loss: 0.8367\n",
            "Epoch [1/1], Step [95/112], Loss: 0.8104\n",
            "Epoch [1/1], Step [97/112], Loss: 0.8239\n",
            "Epoch [1/1], Step [99/112], Loss: 0.8249\n",
            "Epoch [1/1], Step [101/112], Loss: 0.8423\n",
            "Epoch [1/1], Step [103/112], Loss: 0.8405\n",
            "Epoch [1/1], Step [105/112], Loss: 0.8426\n",
            "Epoch [1/1], Step [107/112], Loss: 0.8290\n",
            "Epoch [1/1], Step [109/112], Loss: 0.8072\n",
            "Epoch [1/1], Step [111/112], Loss: 0.8393\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           b       0.59      0.71      0.64     23193\n",
            "           t       0.72      0.43      0.54     21669\n",
            "           e       0.66      0.83      0.73     30494\n",
            "           m       0.81      0.48      0.60      9128\n",
            "\n",
            "    accuracy                           0.65     84484\n",
            "   macro avg       0.69      0.61      0.63     84484\n",
            "weighted avg       0.67      0.65      0.64     84484\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torchtext.vocab import GloVe\n",
        "\n",
        "input_size = 300  # Assuming 300-dimensional GloVe embeddings\n",
        "output_size = 4\n",
        "hidden_size = 100  # 1st layer and 2nd layer number of features\n",
        "num_epochs = 1\n",
        "batch_size = 3000\n",
        "learning_rate = 0.02\n",
        "\n",
        "label_mapping = {\"b\": 0, \"t\": 1, \"e\": 2, \"m\": 3}\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove = GloVe(name=\"6B\", dim=300)\n",
        "\n",
        "# Tokenization and embeddings using spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "\n",
        "\n",
        "def get_average_embedding(text):\n",
        "    tokens = nlp(text)\n",
        "    embeddings = [\n",
        "        glove[token.text].numpy() for token in tokens if token.text in glove.stoi\n",
        "    ]\n",
        "    if embeddings:\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    else:\n",
        "        return np.zeros(input_size)  # Return zeros if no embeddings are found\n",
        "\n",
        "\n",
        "# Apply tokenization and embeddings to the dataset\n",
        "training_data[\"EMBEDDING_GLOVE\"] = training_data[\"TITLE\"].apply(get_average_embedding)\n",
        "testing_data[\"EMBEDDING_GLOVE\"] = testing_data[\"TITLE\"].apply(get_average_embedding)\n",
        "\n",
        "# Convert embeddings to torch tensors\n",
        "train_embeddings = torch.tensor(np.vstack(training_data[\"EMBEDDING_GLOVE\"].to_numpy()))\n",
        "test_embeddings = torch.tensor(np.vstack(testing_data[\"EMBEDDING_GLOVE\"].to_numpy()))\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(training_data[\"CATEGORY\"].map(label_mapping).to_numpy())\n",
        "test_labels = torch.tensor(testing_data[\"CATEGORY\"].map(label_mapping).to_numpy())\n",
        "\n",
        "# Instantiate the model\n",
        "model = NewsNN(input_size, hidden_size, output_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(train_embeddings), batch_size):\n",
        "        inputs = train_embeddings[i : i + batch_size]\n",
        "        labels = train_labels[i : i + batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.float())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if ((i / batch_size) + 1) % 2 == 0:\n",
        "            print(\n",
        "                \"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\"\n",
        "                % (\n",
        "                    epoch + 1,\n",
        "                    num_epochs,\n",
        "                    i / batch_size,\n",
        "                    len(train_embeddings) / batch_size,\n",
        "                    loss.data,\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "# Evaluate on the test set\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(test_embeddings.float())\n",
        "    _, test_predictions = torch.max(test_outputs, 1)\n",
        "\n",
        "test_predictions = test_predictions.numpy()\n",
        "test_labels = test_labels.numpy()\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels, test_predictions, target_names=label_mapping))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

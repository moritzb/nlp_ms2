{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment <span style=\"color:red\">option Four</span> - News Categorization  using PyTorch \n",
    "Download the dataset from https://www.kaggle.com/uciml/news-aggregator-dataset and develop a news classification or categorization model. The dataset contain only titles of a news item and some metadata. The categories of the news items include one of: –<span  style=\"color:red\"> b</span> : business – <span  style=\"color:red\">t</span> : science and technology – <span  style=\"color:red\">e</span> : entertainment and –<span  style=\"color:red\">m</span> : health. \n",
    "\n",
    "1. Prepare training and test dataset: Split the data into training and test set (80% train and 20% test). Make sure they are balanced, otherwise if all <span  style=\"color:red\">b</span> files are on training, your model fails to predict <span  style=\"color:red\">t</span> files in test.\n",
    "2. Binary classification: produce training data for each two categories, such as <span  style=\"color:red\">b </span> and <span  style=\"color:red\"> t</span>, <span  style=\"color:red\">b</span> and <span  style=\"color:red\"> m</span>, <span  style=\"color:red\">e</span> and <span  style=\"color:red\">t</span> and so on. Evaluate the performance and report which categories are easier for the models.\n",
    "3. Adapt the Text Categorization PyTorch code (see above) and evaluate the performance of the system for these task\n",
    "4. Use a pre-trained embeddings and compare your result. When you use pre-trained embeddings, you have to average the word embeddings of each tokens in ach document to get the unique representation of the document. DOC_EMBEDDING = (TOKEN1_EMBEDDING + ... + TOKENn_EMBEDDING). You can also use some of the <span  style=\"color:red\">spacy/FLAIR </span>document embedding methods\n",
    "6. Report the recall, precision, and F1 scores for both binary and multi-class classification.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare training and test dataset: Split the data into training and test set (80% train and 20% test). Make sure they are balanced, otherwise if all <span  style=\"color:red\">b</span> files are on training, your model fails to predict <span  style=\"color:red\">t</span> files in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.11/site-packages (2.1.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./.local/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.local/lib/python3.11/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./.local/lib/python3.11/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.16.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdaten:  337935\n",
      "Testdaten:  84484\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Daten einlesen\n",
    "# data = pd.read_csv(\"./data/uci-news-aggregator.csv\")\n",
    "data = pd.read_csv(\"./uci-news-aggregator.csv\")\n",
    "# Daten in Features (X) und Labels (y) aufteilen: Wenn mehr features, dann die weiteren hinzufügen\n",
    "X = data[['TITLE', 'PUBLISHER', 'CATEGORY']]\n",
    "X = data[['TITLE', 'CATEGORY']]\n",
    "y = data['CATEGORY']\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Aufteilung in Trainings- und Testdaten. Der Parameter stratify führt dazu, dass das feature \"Category\" gleich aufgeteilt sind\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42, stratify=data['CATEGORY'])\n",
    "\n",
    "print(\"Trainingsdaten: \", len(X_train))\n",
    "print(\"Testdaten: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Binary classification: produce training data for each two categories, such as <span  style=\"color:red\">b </span> and <span  style=\"color:red\"> t</span>, <span  style=\"color:red\">b</span> and <span  style=\"color:red\"> m</span>, <span  style=\"color:red\">e</span> and <span  style=\"color:red\">t</span> and so on. Evaluate the performance and report which categories are easier for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–<span  style=\"color:red\"> b</span> : business – <span  style=\"color:red\">t</span> : science and technology – <span  style=\"color:red\">e</span> : entertainment and –<span  style=\"color:red\">m</span> : health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Laden Sie den Datensatz herunter und extrahieren Sie ihn in den Root-Ordner.\n",
    "\n",
    "# Annahme: Der Datensatz befindet sich in der Datei 'newsCorpora.csv' im Root-Ordner.\n",
    "# Stellen Sie sicher, dass Sie die Datei im richtigen Format erhalten (CSV).\n",
    "\n",
    "# Laden Sie den Datensatz\n",
    "dataset_path = '/content/gdrive/MyDrive/uci-news-aggregator.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "df = df[[\"TITLE\", \"CATEGORY\"]]\n",
    "\n",
    "# 1. Vorbereitung des Trainings- und Testdatensatzes\n",
    "# Aufteilung in Trainings- und Testset (80% Train und 20% Test), sicherstellen, dass sie ausgeglichen sind\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['CATEGORY'], random_state=42)\n",
    "\n",
    "# 2. Binäre Klassifikation für jede Kombination von zwei Kategorien\n",
    "categories = ['b', 't', 'e', 'm']\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    for j in range(i + 1, len(categories)):\n",
    "        category_pair = [categories[i], categories[j]]\n",
    "        print(f\"\\nBinary Classification: {category_pair}\")\n",
    "\n",
    "        # Filtern Sie die Daten für die ausgewählten Kategorien\n",
    "        train_data = train_df[train_df['CATEGORY'].isin(category_pair)]\n",
    "        test_data = test_df[test_df['CATEGORY'].isin(category_pair)]\n",
    "\n",
    "        # Extrahieren Sie Titel und Labels\n",
    "        X_train, y_train = train_data['TITLE'], train_data['CATEGORY']\n",
    "        X_test, y_test = test_data['TITLE'], test_data['CATEGORY']\n",
    "\n",
    "        # Textvektorisierung\n",
    "        vectorizer = CountVectorizer()\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "        # Modelltraining (hier: Naive Bayes)\n",
    "        model = MultinomialNB()\n",
    "        model.fit(X_train_vec, y_train)\n",
    "\n",
    "        # Vorhersagen\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "\n",
    "        # Evaluierung der Leistung\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "        print(\"---------------------\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
